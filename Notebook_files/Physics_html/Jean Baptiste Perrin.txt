 Nobel Lecture, December 11, 1926 Discontinuous Structure of Matter Since I have the great honour to have to summarize here the work which has enabled me to receive the high international distinction awarded by the Swedish Academy of Sciences, I shall speak of the “discontinuous structure of matter”. Introduction A fluid such as air or water seems to us at first glance to be perfectly homogeneous and continuous; we can put more water or less water into this glass, and the experiment seems to suggest to us that the amount of water contained in it can vary by an infinitely small amount, which is the same as saying that water is “indefinitely divisible”. Similarly, a sphere of glass or of quartz, a crystal of alum, are received by our senses as being perfectly continuous, and particularly when we see this alum crystal growing in a supersaturated solution, each of the planes bounding the crystal moves parallel to itself in a continuous manner. However, this can be taken for granted only up to the degree of subtlety reached by the resolving power of our senses which, for example, would certainly be unable to distinguish between two positions of the crystal face one millionth of a millimetre apart. Beyond the things which our senses separate in this manner, our imagination remains free, and ever since ancient times, just as the philosophers who started from the ” full” or the “void”, has hesitated between two hypotheses. For the former, matter remains continuous: “full”, not only (as is reasonable and probable) a little beyond this domain on our scale where our senses make it appear as such, but indefinitely. For the latter, who were the first atomists, all matter consists of minute grains separated by empty gaps; not any hypothesis has been formulated for the structure of these grains themselves, atoms, which were considered as indestructible constituent elements of the Universe. Lastly, and doubtless always, but particularly at the end of the last century, certain scholars considered that since the appearances on our scale were finally the only important ones for us, there was no point in seeking what might exist in an inaccessible domain. I find it very difficult to understand this point of view since what is inaccessible today may becomes accessible tomorrow (as has happened by the invention of the microscope), and also because coherent assumptions on what is still invisible may increase our understanding of the visible. Indeed, increasingly numerous and strong reasons have come to support a growing probability, and it can finally be said the certainty, in favour of the hypothesis of the atomists. There is, first of all, the familiar observation of solutions; we all say, for example, that sugar and water are present in sugar water, although it is impossible to distinguish the different parts in it. And similarly, we recognize quite simply bromine in chloroform. This can be understood if the bromine and the chloroform are formed respectively by very small particles in continuous movement which can intermingle with one another without losing their individuality. Those elementary constituent particles, those molecules, are probably of the same kind, like articles made in series, for each pure substance (defined by its resistance to the fractionation test) or even more surely for each definite chemical species (experiment proves that it is never necessary to consider a continuous sequence of chemical species), and we come to formulate the molecular hypothesis by saying that for a sufficient magnification any fluid appears to us as formed by molecules in continuous movement which impinge ceaselessly upon one another, and of which there are as many distinct varieties as chemical species can be recognized in the fluid under consideration. These molecules which exist in the mixtures are not indestructible since they must disappear (or appear) when a chemical reaction causes the chemical species which they constitute to disappear (or appear); when a mixture of hydrogen and oxygen explodes to give water, the molecules of hydrogen and oxygen certainly have to disappear at the same time as the water molecules appear. But we know that the decomposition of chemical species, when carried out as far as possible, has led to the experimental definition of a small number of simple bodies which can always be recovered, without any change in their nature, and without loss or gain of mass, from combinations in which they have been introduced. It is then very difficult not to assume that, for example, one and the same substance “exists” in all the chemical species from which the simple substance hydrogen can be regained and which passes, disguised but indestructible, through our various reactions. Dalton supposed, and this is the essential point of the atomic hypothesis, that this substance is formed by a definite variety of particles which are all identical and which cannot be cut into pieces in the reactions which we can produce, and which for this reason are called atoms. There are, therefore, one or several atoms of hydrogen in each molecule of a hydrogenated chemical species. The fundamental laws of chemistry which are well known to you and which are laws of discontinuity (discontinuity between chemical species, and discontinuous variation according to the ” multiple proportions” in the composition of species made from the same simple bodies) then become immediately clear: they are imposed solely by the condition that the molecule constituting a compound contains a necessarily whole number of atoms of each of the simple bodies combined in this compound. And I do not need to tell you that if one admits that ” analogous ” bodies (alkali halides, for example) must have analogous formulae, simple chemical analysis will give for the elements of the same ” family” the ratios of the weights of the atoms, or “atomic weights”, of these elements. But in order to pass from one family to another, from hydrogen to oxygen for example, it was necessary to have the gas laws and Avogadro’s hypothesis or law which I recall because my researches are based on it: when one of those cases occurs where the ratios of the weights of the molecules of the two compounds are known, it is found that masses proportional to these masses (which must, therefore, contain the same number of molecules) occupy equal volumes in the gaseous state under the same conditions of temperature and pressure. This means that as far as these substances are concerned, equal numbers of heavy or light molecules develop equal pressures at the same temperature and in equal volumes. Since the mass of a molecule, and not its nature, must affect the impact of the molecule upon the wall, I see here a justification (not yet agreed, I must say) of the following proposition known as Avogadro’s postulate, or hypothesis: When gaseous masses, at the same temperature and pressure, occupy equal volumes, they all contain the same number of molecules. These “equimolecular” masses are determined for the various chemical species, as soon as one of them has been chosen. They are called gram-molecules when the masses in the gaseous state occupy, at the same temperature and pressure, the same volume as 32 grams of oxygen. The number N of the molecules constituting any gram-molecule is Avogadro’s number. For each simple substance the gram-molecule of a compound contains as many gram-atoms as the molecule contains atoms of this simple substance, and the gram-atom is the product of the mass of the atom and Avogadro’s number N. In short, if molecules and atoms exist, their relative weights are known to us, and their absolute weights would be known at the same time as Avogadro’s number. You also know how – particularly for understanding substitutions – it was assumed that the atoms of a molecule are held together by valences of which each unites only two atoms, a kind of bolt holding rigidly together two bars or protuberances which pre-exist on the two atoms. A new detail is thus introduced here to the concept of the atom, but once this new hypothesis is accepted, the structural formulae can be determined for an enormous number of compounds, and with such success in regard to forecasting the properties that it could be said that the hundreds of thousands of structural formulae set up by the organic chemists constitute just as many arguments in favour of the atomic theory. These brilliant successes tell us, otherwise, nothing about the absolute weights of the atoms. If they all became at the same time a thousand times smaller, a milliard times smaller, infinitesimal in the mathematical sense of the word, with matter becoming again continuous at each reduction, our chemical laws and our formulae would be unchanged, and the idea of the atom, then driven back infinitely far beyond all experimental reach, would lose its interest and its reality. It will be noted that the laws of crystallography, which are laws of discontinuity just as the fundamental laws of chemistry, lead to similar considerations in regard to the dimensions of an elementary cell which is repeated periodically along the three dimensions of a parallelepipedic lattice and should constitute the crystal which is homogeneous in appearance on our scale. Only in this way can one understand how the symmetries of crystals are soley those of reticular systems (for example, never symmetry axes of the order of 5), and explain at the same time the law of rational indices (a kind of laws of multiple proportions which describe what discontinuities separate the possible faces), a law which requires the three dimensions of the elementary parallelepiped to be in definite ratios. Here again the grain of matter could become infinitely small without the laws having to be changed. In short, in order really to establish the Atomic Theory, it was necessary to obtain the weights and dimensions of the atoms and not only their ratios. A remarkably successful attempt to do this was made about fifty years ago by the physicists who created the kinetic theory of gases by assuming that gases are made of elastic molecules which are on the average fairly widely separated from one another so that, between two collisions, each molecule can move in a straight line, the duration of the collision being negligible in relation to that of the free path. Furthermore, if it is agreed that the pressure of a gas on a wall is solely due to the impacts of the molecules upon this wall, and if we write that this (known) pressure must consequently be numerically equal to the impulse exerted perpendicularly on the wall by the molecules impinging against unit surface in unit time, an equation is obtained which shows the mean velocity of the gas molecules. It is also known that if, in a gas, a rigid plane is made to slide parallel to a fixed plane at a distance D and with a constant velocity V, each intermediate layer at a distance d from the fixed plane is involved with a velocity equal to V(d/D), and that the fixed and moving planes are drawn in opposite directions by forces (per unit surface) equal to the product of the velocity gradient V/D and a fixed factor for each gas, the latter measuring the viscosity of this gas (at the temperature of the experiment). This is readily understood from the kinetic theory: the unit surface of the fixed plane is drawn in the direction of the movement by a force numerically equal to the total excess impulse received in this direction, this excess being proportional to the number of impinging molecules (in other words, both to the density and to the mean molecular velocity which we can determine), and proportional to the mean excess impulse of each impinging molecule; this individual mean excess is itself proportional to the distance of the layer in which the molecule was at the time of the previous impact, and consequently to the mean free path. In this way it is seen how Maxwell was able to deduce this mean free path from the experimental determination of the viscosity. Now, as Clausius observed, the molecules are all the smaller as the mean free path (now known) becomes greater (if the molecules were reduced to points, they would never collide with one another). And it is seen, therefore, that if the free path is known, it is possible to calculate the total surface of the molecules which form a given mass of gas. The total volume of these same molecules is probably little different from the volume occupied by this mass if it were solidified. Finally, from two obvious equations we derive both the number and the diameter of the molecules which constitute, let us say, a gram-molecule of the gas. Depending on the gas, the diameters found in this way are graded between 2 and 5 ten-millionths of a millimetre; and the values found for Avogadro’s number are between 40 x 1022 and 120 x 1022. The uncertainty is largely 100 per cent, both because of the inaccuracy of certain measurements and especially because the calculations have been simplified by making assumptions which can only be approximate. But the order of magnitude is achieved: an atom vanishes in our substance almost as the latter would vanish in the sun The sequence of reasonings which I have just summarized deserves our profound admiration; however, they were not sufficient to carry conviction owing to the uncertainty which in spite of everything existed not only in the simplifying assumptions (sphericalness of the molecules, for example), but in the very hypotheses on which the reasoning is based. This conviction will without doubt come to life if entirely different paths lead us to the same values for the molecular sizes. The Brownian movement Let us consider a liquid in equilibrium: the water contained in this glass, for example. It appears to us homogeneous and continuous, and immobile in all its parts. If we place in it a denser object, it falls, and we know quite well that once it has arrived at the bottom of the glass, it stays there and is unlikely to ascend again “by itself”. We could have observed this water before it reached equilibrium, and to see how it reached it, at the moment when we filled this glass; then we should have been able to find (by observing the visible indicator dust which was specially mixed with the water) that the movement of the various parts of the water which were coordinated at first in parallel movements, became more and more uncoordinated by scattering in all directions between smaller and smaller parts until the whole appeared completely immobile (nothing prevents us as yet from assuming that this scattering will continue without limit). It is very remarkable that these so familiar ideas become false on the scale of the observations which we can make under a microscope: each microscopic particle placed in water (or any other liquid), instead of falling in a regular manner exhibits a continuous and perfectly irregular agitation. It goes to and fro whilst turning about, it rises, falls, rises again, without tending in any way towards repose, and maintaining indefinitely the same mean state of agitation. This phenomenon which was predicted by Lucretius, suspected by Buffon, and established with certainty by Brown, constitutes the Brownian movement. The nature of the grains is not important, but the smaller a grain is, the more violently does it become agitated. There is also complete independence between the movements of two grains, even if they are very close together, which excludes the hypothesis of collective convection produced by the impacts or temperature differences. We are, finally, forced to think that each grain only follows the portion of liquid surrounding it, in the same way that an indicating buoy indicates and analyses the movement all the better if it is smaller: a float follows the movement of the sea more faithfully than a battleship. We obtain from this an essential property of what is called a liquid in equilibrium: its repose is only an illusion due to the imperfection of our senses, and what we call equilibrium is a certain well-defined permanent system of a perfectly irregular agitation. This is an experimental fact in which no hypothesis plays any part. Since this agitation remains on an average constant (it would be possible to make this “impression” accurate by measurements), the movement possessed by a part of the liquid does not scatter without limit in all directions between smaller and smaller parts, in spite of what observations made on our scale suggest to us; this spreading does not go beyond a certain limit for which, at each moment, just as much movement is coordinated as becomes uncoordinated. This is explainable if the liquid consists of elastic grains, and I do not see how it can be understood if the structure is continuous. Moreover, it is seen that the agitation for a given observable particle must increase with the size of the molecules: the magnitude of the Brownian movement, therefore, will probably enable us to calculate the molecular sizes.* In short, the Brownian movement (an experimental fact) leads us to the hypothesis of the molecules; and we then understand quite well how each particle that is situated in a liquid and is being bombarded ceaselessly by neighbouring molecules, receives shocks which on the whole have all the less change of coming to equilibrium as the particle becomes smaller, with the result that this particle must be tossed to and fro irregularly. This applies to absolutely whatever kind of particle. If it has been possible to bring into suspension in a liquid a large number of particles all of the same nature, we say that an emulsion has been produced. This emulsion is stable if the particles in suspension do not stick together when the hazards of the Brownian movement bring them into contact, and if they re-enter the liquid when these hazards bring them against the walls or to the surface. From this two-fold point of view such a stable emulsion is comparable to a solution. It is precisely by pursuing this analogy that I have been able to obtain a simple determination of the molecular sizes. Extension of the gas laws to emulsions I must, first of all, recall how the gas laws and particularly Avogadro’s law came to be regarded, thanks to Van ‘t Hoff, as applicable to dilute solutions. The pressure exerted by a gas on the walls limiting its expansion becomes, for a dissolved substance, the osmotic pressure exerted on semi-permeable walls which allow the solvent to pass, but hold back this dissolved substance. Such is a membrane of copper ferrocyanide which separates sugared water from pure water. Now, the measurements of Pfeffer show that in fact the equilibrium exists only if there is a certain excess pressure from the side on which the sugar is, and Van ‘t Hoff has pointed out that the value of this excess pressure or osmotic pressure is precisely that of the pressure which would be exerted, in accordance with Avogadro’s law, on the wall of the container containing the sugared water if the sugar present could occupy the entire container alone and in the gaseous state. It is then probable that the same would occur with every dissolved substance, but we do not need to recall the thermodynamic reasoning with which Van ‘t Hoff justified this generalization nor to make other measurements of the osmotic pressure: Arrhenius has indeed shown that every substance which, in solution, confirms the well-known Raoult laws through its freezing temperature and its vapour pressure, necessarily exerts through this very fact the pressure predicted by Van ‘t Hoff on every wall which halts it without halting the solvent. In short, the Raoult laws which were established by a very large number of measurements, are logically equivalent to the law of Van’t Hoff which consists in the extension of Avogadro’s law to solutions, and we can now say: Equal numbers of molecules, regardless of the kind, in the gaseous state or dissolved, exert – at the same temperature and in equal volumes – equal pressures on the walls detaining them. This law applies equally to heavy or light molecules, in such manner that, for example, the molecule of quinine which contains more than one hundred atoms, has neither a greater nor a lesser effect when it impinges against the wall than the light molecule of hydrogen which contains two atoms. I have thought that it was perhaps valid for stable emulsions with visible grains, in such manner that each of these grains which is agitated by the Brownian movement, counts as a molecule when it collides with a wall. Let us assume then that we can measure the osmotic pressure which equal grains exert, through their Brownian movement, against a unit of a wall which holds them up and allows water to pass (let us say blotting paper). Let us also assume that we can count these grains in the immediate vicinity of the wall unit, that is to say that we know the “abundance” of the grains per unit volume near this wall unit. This number n also measures the abundance of molecules in any gas (let us say hydrogen) which would exert the same pressure on the walls of the container in which it would be enclosed. If, for example, the osmotic pressure measured is the hundred-millionth of a barye, we shall know that a cubic centimetre of hydrogen under normal conditions (pressure equal to a million baryes) contains 100 million million times n molecules (1014 n). And the gram-molecule (22,412 c.c. in the gaseous state under normal conditions) will contain 22,412 times more molecules: this number will be Avogadro’s number. This is very simple; but how to measure the stupendously weak osmotic pressure that an emulsion exerts? This will, in fact, not be necessary nor, as we have just explained, will it be necessary to measure the osmotic pressure of a solution to make sure that this solution obeys the gas laws. And it will be sufficient for us to find an experimentally accessible property for emulsions which would be logically equivalent to the gas laws. I found such a property (1908) by extending to emulsions the fact that is qualitatively well known to you, that in a vertical column of a gas in equilibrium the density decreases as the altitude increases. Law of the vertical distribution of an emulsion We all know that air is more rarefied at the top of a mountain than at sea level and, generally speaking, he pressure of air has to diminish as one goes higher since this pressure has then to carry only a smaller part of the atmosphere which applies its weight against the earth. If we specify this slightly vague reasoning in the Laplace manner, we shall say that each horizontal slice of a gas in equilibrium in a large vertical pump would remain in equilibrium if it were imprisoned between two rigid pistons (which would no longer allow exchange of molecules between this slice and the neighbouring slices of the gas) and these pistons would exert respectively the pressures existing at the lower face and at the upper face of the slice; with the result that, per unit surface, the difference of these pressures is equal to the weight of the gas supported. That is to say that if the thickness dh of the slice is sufficiently small so that the abundance of molecules near the upper face differs little from the abundance n near the lower face, the pressure difference dp between the two faces will be equal to n p dh, where p denotes the weight of a molecule. This very simple equation expresses two important facts: first of all, as the abundance n of molecules is proportional to the pressure p at each given temperature, we see that for a column of a given gas (for a given p) and of uniform temperature, the relative reduction of the pressure dp/p, or also the relative reduction of the abundance dn/n which can be said to measure the rarefaction, always has the same value for the same difference in level dh, whatever this level may be. For example, each time that you climb a flight of stairs, the pressure in the air (or the abundance of molecules) is reduced by one forty-thousandth of its value. Adding these effects for each step, we see that at whatever level we were originally, each time we ascend by the same height, the pressure (or the density) in air at a uniform temperature will be divided by the same number; for example, in oxygen at 0° the rarefaction will be doubled for each rise of 5 kilometres. The other fact which emerges immediately from our equation relates to the weight p of the molecule; for the same value of level dh, the rarefaction dp/p (or dn/n) varies in inverse ratio with the weight of the molecule. Adding here again the effects for each step, we see that in two different gases at the same temperature, the rises producing the same rarefaction are in inverse ratio to the molecular weights. For example, as we know that the oxygen molecule (if it exists, and in accordance with the laws summarized above) must weigh 16 times more than the hydrogen molecule, it is necessary to rise 16 times higher in hydrogen than in oxygen, i.e. 80 kilometres, for the rarefaction to be doubled. You can appreciate the influence of the altitude, and of the molecular weight, on the rarefaction by looking at this schematic picture where I have drawn three gigantic vertical test tubes (the highest is 300 kilometers) containing equal numbers of hydrogen molecules, helium molecules, and oxygen molecules. At a uniform temperature the molecules would be distributed as shown in the drawing, being more numerous near the bottom as they increase in weight. Let us now admit that Avogadro’s law applies to emulsions as it does to gases. We assume, therefore, that we have a stable emulsion made of equal grains which is left to itself at a constant temperature, being only under the influence of its own weight. We can repeat the previous reasoning with the only change that the intergranular space, instead of being void, is now a liquid which exerts on each grain, in an opposite direction to its weight, a push in accordance with Archimedes’ principle. Consequently, the effective weight z of the gram to which this reasoning is applied, is its actual weight reduced by this push. If now our generalization is justified, once the emulsion is in equilibrium it will produce a miniature atmosphere of visible molecules where equal rises will be accompanied by equal rarefactions. But if, for example, the rise in the emulsion to double the rarefaction is a milliard times less than in oxygen, it means that the effective weight of the grain is a milliard times greater than that of the oxygen molecule. It will, therefore, be sufficient to determine the effective weight of the visible grain (which forms links between the magnitudes on our scale and the molecular magnitudes) in order to obtain by a simple ratio the weight of any molecule, and consequently Avogadro’s number. It is in this sense that I carried out my experiments which I was able to do successfully. I first prepared stable emulsions made from solid (vitreous) spheres of various resins in suspension in a liquid (generally water). This was done by dissolving the resin in alcohol and adding to this limpid solution a large amount of water. The resin is quite insoluble in the water and is then precipitated as microscopic spherules of all sizes. By means of prolonged centrifuging similar to those in which the red blood corpuscles are separated from the blood serum, it is possible to collect these grains as a consistent deposit which splits up again as a stable emulsion of distinct spherules when it is agitated in the pure water after the supernatant alcohol solution has been removed. It was then necessary, starting with an emulsion where the grains are of very different size, to succeed in separating these grains according to size in order to have uniform emulsions (consisting of equal grains). The process which I used can be compared with fractional distillation: just as, in a distillation, the fractions which come off first are richer in the most volatile constituents, so in a centrifuging of a pure emulsion (spherules of the same substance), the parts which settle out first are richer in coarse grains, and this is a method of separating the grains according to size by proceeding according to rules which it would be unnecessary to elaborate here. It is also necessary to be patient: I treated in my most careful fractionation one kilogram of gamboge and obtained after several months of daily operations a fraction containing several decigrams of grains with a diameter of approximately three-quarters of a thousandth of a millimetre which was appreciably equal to what I had wanted to obtain. If a droplet of a very dilute emulsion made with such equal grains is allowed to evaporate on the slide under a microscope, the grains are seen, when the evaporation is almost complete (and doubtless as a result of capillary action), to run and join together in regular lines just as cannon-balls in a horizontal row of a pile of cannon-balls. You can see this on the photograph which is now projected. And you will understand how it is possible simultaneously to obtain a successful centrifuging and to measure the mean diameter of the grain of the emulsion. (Other processes are, moreover, possible.) On the other hand, there is no difficulty in determining the density of the glass constituting the spherules (several processes: the most correct consists in suspending the grains in a solution which is just so dense that the centrifuging cannot separate the grains). We then know everything necessary for calculating the effective weight of the grain of the emulsion. On the other hand, we shall have studied the equilibrium distribution of the emulsion under the action of gravity. For this we imprison a drop of the emulsion in a well-closed dish (evaporation must be impossible) arranged for microscopic observation. The distribution of the grains is at first uniform, but it is found that the grains accumulate progressively in the lower layers until a limiting distribution is reached with reversible settling or expansion depending on whether the temperature is lowered or raised. There are two possible methods of observation, as shown in the drawing projected here. In one method (the horizontal microscope) the rarefaction of the emulsion is obtained immediately from the height, and the resemblance to a miniature atmosphere is extremely striking, precise measurements being possible from instantaneous photographs. But it is then difficult to give the emulsion a height lower than, shall we say, one millimetre, and the time needed for establishing a permanent state becomes long (several days) which involves complications and difficulties. In the other method of observation the microscope is vertical, and the emulsion imprisoned between the slide and the cover-glass has now a thickness only of the order of a tenth of a millimetre. We take an objective of high magnifying power and weak focal depth so that a very thin horizontal layer of the emulsion (of the order of 2 microns) is clearly seen, and an instantaneous photograph is taken. We thus have the abundance at a certain level (as an aviator could take the density of air at every level). The abundances at different levels are then compared at our leisure. The success is complete. Before insisting that it is so, I can show a cinematographic film on which you will see for yourselves the equilibrium distribution of an emulsion formed from spherules which are agitated by the Brownian movement. The observations and the countings which this film summarizes for you prove that the laws of ideal gases apply to dilute emulsions. This generalization was predicted as a consequence of the molecular hypothesis by such simple reasoning that its verification definitely constitutes a very strong argument in favour of the existence of molecules. In particular, it was necessary – it can be verified effectively, and it is very remarkable – that the various emulsions studied lead, within the limit of the possible errors, to the same value for Avogadro’s number. In fact, I changed (with the valuable assistance of Bjerrum, Dabrovski, and Bruhat) the mass of the grains (from 1 to 50), their nature (gamboge, mastic), their density (1.20 to 1.06), the nature of the intergranular liquid (water, strongly sugared water, glycerol in the upper layers of which the grains of mastic, being lighter, accumulated) and lastly the temperature (from -9° to +60°). My most careful measurements made with an emulsion the rarefaction of which doubled with each rise of 6 microns, gave a value for N of 68 X 1022. The accuracy of such determinations, so far of several hundredths, can certainly be improved: the same does not apply to values obtained from the kinetic theory of gases, because here perfecting the measurements would not diminish the uncertainties inherent in the simplifying assumptions which were introduced to facilitate the calculations. Non-diluted emulsions Proceeding then further in tracing the similarities between liquids and emulsions, I was able to show (1913) that a non-diluted emulsion is comparable to a compressed liquid of which the molecules would be visible. For this purpose it was necessary to determine the osmotic pressure as a function of the concentration when the gas laws cease to be applicable. Let us, therefore, consider a vertical column of emulsion which extends upwards practically without limit. At each level the osmotic pressure can be regarded as supporting the whole of the grains above it, and we shall, therefore, know it by counting all these grains. The emulsion will be imprisoned between two vertical plate glasses only several microns apart so that all the grains can be taken by an instantaneous photograph. The concentration of the grams at each level is, on the other hand, fixed by the known number of grains present in a small known volume near this level. In short, we shall in this way know the pressure corresponding to a known concentration: this will give experimentally the law of compressibility which can then be compared with Van der Waals’ law. Rene Costantin made these measurements under my direction and confirmed that Van der Waals’ law applies to emulsions which are already too concentrated to conform to the gas laws. The resulting value for Avogadro’s number is 62 x 1022. Even Van der Waals’ law is no longer suitable for concentrations above 3 per cent, but the compressibility remains measurable, consequently the law of compressibility remains known empirically. This enables – and this idea was due entirely to René Costantin who died for France in 1915 – a theory of Smoluchovski to be checked on the density fluctuations which the molecular agitation should produce in a liquid in equilibrium. According to this theory, the fluctuation (n’-n)/n in a volume containing accidentally n’ molecules whilst it should contain only n if the distribution were uniform, has a mean value which can be calculated if the compressibility of the liquid is known, and which includes Avogadro’s number. For our emulsions of equal grains, considered as fluids with visible molecules, the measurements of osmotic compressibility, carried out as far as a content of 7 per cent, have confirmed Smoluchovski’s theory by giving approximately 60 X 1022 for Avogadro’s number. Measurements of the Brownian movement The equilibrium distribution of an emulsion is due to the Brownian movement, and the more rapidly as this movement is more active. But this rapidity is not important for the final distribution. In fact, as we have just seen, I also studied the distribution first on the permanent state without making any measurement on the Brownian movement. But by means of such measurements it is possible, though in a less obvious manner, to demonstrate the discontinuous structure of matter and to obtain a determination of Avogadro’s number. It is due to Einstein and Smoluchovski that we have a kinetic theory of the Brownian movement which lends itself to verification. Without being disturbed by the intricate path described by a grain within a given time, these physicists characterize the agitation by the rectilinear segment joining the point of departure with the point of arrival, the segment being on an average greater as the agitation is livelier. This segment will be the displacement of the grain during the time considered. If we then admit that the Brownian movement is perfectly irregular at right angles to the vertical, we prove that the mean horizontal displacement of a grain is doubled when the duration of the displacement is quadrupled, and is tenfold if that duration becomes a hundredfold, and so forth. This means that the mean square of the horizontal displacement is proportional to the duration t of this displacement. This can easily be verified. Now, this mean square is equal to twice the mean square of the projection of the displacement on an arbitrary horizontal axis. Consequently, the mean value of the quotient for a given grain remains constant. Obviously, since it increases as the grain is more agitated, this mean quotient characterizes the activity of the Brownian movement. Having said this, there must be a diffusion for the grains of an emulsion just as for the molecules of a solution; Einstein shows that the coefficient of diffusion should be equal to the half of the number which measures the activity of the agitation. On the other hand, the steady state in a vertical column of emulsion is produced and maintained by the interplay of two opposing actions, gravity and the Brownian movement; this can be expressed by writing that at each level the flow through diffusion towards the poor regions is equal to that which gravity produces towards the rich regions. In order to calculate the flow by diffusion it must be admitted, as we have done, that grains or molecules are equivalent to each other in regard to the osmotic pressures; in order to calculate the flow produced by gravity, in the case of spherules of radius a, it must be admitted, though at first it appeared uncertain, that the (very weak) mean velocity of fall of a grain animated by a very active Brownian movement can still be calculated by “Stokes’ law” which applies to the uniform fall in a viscous liquid of a large sphere which is practically not animated by a Brownian movement. In fact, I have since shown experimentally that this is so. Having admitted this hypothesis, Einstein finds that the diffusion coefficient is equal to (RT/N) (6paz)-1 (R being the gas constant, T the absolute temperature, and z the viscosity). So far we have thought of the translational Brownian movement only. Now a grain rotates at the same time as it is displaced. Einstein was able to show that if denotes the mean square in a time t of the component of the angle of rotation around an axis, the agitation coefficient of rotation is fixed for the same grain and should be equal to (RT/N) (4pa3z)-1. His reasoning implies equality between the mean energy of translation and the mean energy of rotation which was predicted by Boltzmann and which we shall make more probable if we succeed in confirming this equation. These theories can be judged by experiment if we know how to prepare spherules of a measurable radius. I was, therefore, in a position to attempt this check as soon as I knew, thanks to Langevin, of the work of Einstein. I must say that, right at the beginning, Einstein and Smoluchovski had pointed out that the order of magnitude of the Brownian movement seemed to correspond to their predictions. And this approximate agreement gave already much force to the kinetic theory of the phenomenon, at least in broad outline. It was impossible to say anything more precise so long as spherules of known size had not been prepared. Having such grains, I was able to check Einstein’s formulae by seeing whether they led always to the same value for Avogadro’s number and whether it was appreciably equal to the value already found. This is obtained for the displacements by noting on the camera lucida (magnification known) the horizontal projections of the same grain at the beginning and at the end of an interval of time equal to the duration chosen, in such a manner as to measure a large number of displacements, for example in one minute. In several series of measurements I varied, with the aid of several collaborators, the size of the grains (in the ratio of I to 70,000) as well as the nature of the liquid (water, solutions of sugar or urea, glycerol) and its viscosity (in the ratio of 1 to 125). They gave values between 55 x 1022 and 72 x 1022, with differences which could be explained by experimental errors. The agreement is such that it is impossible to doubt the correctness of the kinetic theory of the translational Brownian movement. It must otherwise be observed that although it is didactically of comparable difficulty to the kinetic theory of the viscosity of gases, Einstein’s theory does not introduce simplifying approximations and, like the measurement of height distribution, lends itself to a precise determination of Avogadro’s number. My most careful measurements which gave me N equal to 69 x 1022 had been made on grains which, for reasons which are no longer of interest, had their initial position at 6 µ from the bottom of the preparation. In the course of the verifications which I had asked René Costantin to make on preparations which were only several microns thick, he found that the vicinity of a wall slowed down the Brownian movement. The measurements made at a distance from the walls gave a value for N of 64 x 1022. With regard to the rotational Brownian movement, Einstein’s formula predicts a mean rotation of approximately 8° per hundredth of a second for spheres of 1 µ diameter, a rotation which is too rapid to be perceived and which – with greater reason – escapes measurement. And, in fact, this rotation had not been made the subject of any experimental study, at least not quantitatively. (Einstein did not suppose that his formula could be verified.) I overcame the difficulty by preparing large spherules of mastic. I arrived at them by making pure water pass slowly under an alcohol solution of resin. A passage zone is produced where the grains form which then have generally a diameter of some twelve microns. They are limpid spheres, like glass balls. They frequently seem to be perfect, and then their rotation is not observable. But they also frequently contain small vacuoles, guide marks by means of which the rotational Brownian movement is easily perceived. But the weight of these large grains keeps them very close to the bottom which disturbs their Brownian movement. I, therefore, tried to give the intergranular liquid the density of the grains by dissolving suitable substances in it. A complication soon arose in that at the amount necessary for keeping the grains suspended between the two waters, almost all these substances agglutinated the grains into bunches of grapes, showing thus in the nicest way possible the phenomenon of coagulation which is not easy to obtain on ordinary suspensions or colloidal solutions (of ultramicroscopic grains). Coagulation failed to occur in a single substance, urea. In water containing 27 per cent urea I was, therefore, able to follow the agitation of the grains and to measure their rotation. For this I noted at equal intervals of time the successive positions of certain vacuoles from which it was then possible, at one’s leisure, to find again the orientation of the sphere at each of these moments and to calculate its rotation from one moment to the next. The calculations were made on approximately 200 (fairly rough) gl an e measurements on spheres having a diameter of 13 µ, and gave me for N the value of 65 x 1022 This agreement with the previous . determinations is all the more striking as even the order of magnitude of the phenomenon was not known (1910). The molecular reality Briefly, and in spite of the variety of experimental conditions and techniques, the study of the emulsions gave me for Avogadro’s number: 68 x 1022 by means of the distribution of emulsions analogous to gases; 62 x 1022 by means of that of emulsions analogous to liquids; 60 x 1022 by means of the fluctuations in concentrated emulsions; 64 x 1022 by means of the translational Brownian movement; 65 x 1022 by means of the rotational Brownian movement; or, as a crude average, 64 x 1022. I can recall here that on the other hand, considering gases as consisting of molecules which diffract light (Rayleigh, Smoluchovski, Einstein) it was possible to obtain (somewhat after my first experiments) Avogadro’s number by means of measurements relating to the critical opalescence (Keesom: 75 x 1022 ), the blueness of the sky (Bauer and L. Brillouin, then Fowler: 65 x 1022), and relating in a particularly precise manner to light that was laterally diffused by gases (Cabannes: 65 x 1022; 1921). The theory of black-body radiation, where the reasoning is allied to that of the kinetic theory, gives again the same value (64 x 1022). Along other lines, the measurements of the electric charges of charged microscopic dust, which should be whole multiples of the elementary charge of ions, led – by stages with Townsend, J.J. Thomson, Harold A. Wilson, Ehrenhaft, and finally Millikan (1909) – to the same result (61 x 1022). Lastly, radioactivity which enables the atoms forming a given mass of helium to be counted one by one, has given in a totally different manner proofs of the discontinuity of matter by imposing once again the same value (62 x 1022 to 70 x 1022) on Avogadro’s number. Such a collection of agreements between the various pieces of evidence according to which the molecular structure is translated to the scale of our observations, creates a certitude at least equal to that which we attribute to the principles of thermodynamics. The objective reality of molecules and atoms which was doubted twenty years ago, can today be accepted as a principle the consequences of which can always be proved. Nevertheless, however sure this new principle may be, it would still be a great step forward in our knowledge of matter, and for all that a certitude of a different order, if we could perceive directly these molecules the existence of which has been demonstrated. Without having arrived there, I have at least been able to observe a phenomenon where the discontinuous structure of matter can be seen directly. Monomolecular films I encountered this phenomenon (1913) by observing under the microscope small laminae of “soapy water”, and in such simple conditions that it is surprising it was not discovered earlier. You know the properties of thin laminae: each ray reflected from such a lamina is formed by the superposition of a ray reflected from the front side of the lamina on a ray reflected from the rear side. For each elementary colour these rays add together or subtract from one another according to a classical formula, depending on whether they are in phase or out of phase; in particular, there is extinction when the thickness of the lamina is an even multiple of one quarter of the wavelength, and there is maximum reflection when it is an odd multiple. If, therefore, white light strikes a lamina which has a thickness increasing continuously from zero, the reflected light is at first non-existent (black lamina), then weak (grey lamina), then lively and still almost white, becoming successively straw yellow, orange yellow, red, violet, blue (tints of the first order), then again (but with different tints) yellow, red, violet, blue, green (second order); and so on, the reflected colour becoming continuously more complex and more off-white up to the “white of a higher order” (the spectrum is furrowed with black grooves the number of which increases with the thickness of the lamina). All these tints will be present at the same time on a lamina which has not a uniform thickness and which will be black or grey in its thinnest region, straw yellow in a thicker region, red in an even thicker region, and so forth. It is the same with ordinary soap bubbles, with their magnificent colours. The gradation of these colours seems to us perfectly continuous, from the lowest part of the bubble where the wall is thicker, to its upper part, which thinning progressively, becomes white and then grey, after passing through the “first-order” tints. At that moment, just before the bubble bursts, this thin region: begins to show one or several black spots, quite round, which contrast strongly with the neighbouring grey tone (I mistook them for holes when I was a child) and the very sharp edge of which marks a strong discontinuity in the thickness. In fact, they are not completely black, but reflect so little light that their thickness is certainly small in relation to the wavelengths of white light. In an enclosed space that is free from dust, these black spots may extend over areas of the order of one square decimetre, and remain for several months (Dewar). A more careful examination has long since shown that in the first black spot may form even blacker circles, therefore thinner ones, again with a sharp periphery. In measurements which were at the time very remarkable, although not very accurate, Reinold and Rücker, and then Johonnott had shown that the darkest spot could have a thickness of 6 mµ (milli-microns), and the other roughly twice this. No interpretation had been given: it was simply thought that the surface tension which is variable below a certain thickness, became equal again for the thickness of the two black spots to what it is for large thicknesses. In the light of subsequent observations we shall understand that the black spot represents a kind of carpet formed by two layers or perhaps even by a single layer of molecules held together parallel with one another. Without indicating here the intermediate stages which I passed through, let us say straightaway that, by observing in the microscope in bright light a small horizontal lamina of a given soapy water (approximately 5 per cent pure alkali oleate), I have seen the discontinuities multiplying of which the black spots were the first example. The observation is made as for a metal surface: the light emitted through a lateral aperture in the tube of the microscope and reflected towards the objective, passes it and is reflected on the thin lamina, returning to the eye through the objective and the eye-piece to give a clear image of the lamina. We then see, first of all, the colours in continuous gradation of the ordinary laminae of soapy water; then the lamina quivers; liquid gathers together in globules; at the same time, uniform bands, with flat tints separated from one another by arcs of a circle, appear in the whole lamina which becomes a kind of mosaic. These arcs terminate at the globules around which they radiate like stars. Once this stratification is organized, a very slow evolution takes place by displacement of the contours and the globules, giving (according to circumstances over which I had no control) more or less importance to one band or the other or a series of bands which is the reason for the extraordinary variety of stepped laminae which are observed. Very frequently kinds of flat bulges are seen protruding from the globules or from the non-stratified peripheral liquid and spreading over bands which have already formed. We thus observe, in order of increasing thickness, black bands which do not seem to differ from the ” black spots” which we just mentioned; then grey, white, yellow, red, blue bands; and then bands having second-order tints, and so on, up to higher-order white. Each band has a uniform colour standing out clearly and discontinuously against adjacent bands. The richness of the colours can be extreme as you see from the colour photographs (Lumiere autochrome plates) which are here projected. The richness pertaining partly to a transitional tint – e.g. some purple – represented by an insignificant region on a lamina of ordinary soap, may extend here as a flat tint over an important area. These bands are definitely liquids; this is shown by the existence of exactly circular contours (when solidification occurs, the areas become like dried skins with a dentated contour), by the mobility of these contours which change by blowing without breaking the lamina, by the existence finally of a ” two-dimensional ” Brownian movement which is found (for droplets, or for small flat discs, pieces detached from the bands), on grey or coloured bands (the Brownian movement is all the less lively when these bands are thicker which is natural in view of the fact that the frictions then become more important). Let me add that I have also been able to obtain such stepped laminae with alkali oleate in glycerol, and also with alkali colophonates and resinates in water. Having examined a large number of stratified laminae, it occurred to me, before I made any measurement, that the difference in thickness between two adjacent bands cannot fall below a certain value and that this elementary minimum difference, a kind of “step of a staircase”, is included a whole number of times in each band. Similarly, if we throw playing-cards on the table, the thickness at each point is that of a whole number of cards, without all possible thicknesses being necessarily present, since two or three cards may remain stuck together. The stratified liquid strips would, therefore, be formed by the piling up of identical sheets, more or less overlapping each other, their liquid state imposing on the free contours the form of arcs of a circle (which are fixed at their extremities on globules or on the non-stratified periphery, according to conditions so far unknown). The measurements confirmed this impression. From 1913 onwards I found a value ranging between 4.2 and 5.5 mµ. And since then, precise photometric determinations made under my direction in 1921 by P.V. Wells, who otherwise had to overcome serious experimental difficulties, have fully established what we can call a law of multiple thicknesses. We first of all applied simply the classical relationship between the thickness of the lamina and the intensity of the reflected light, using monochromatic lighting. On the first-order band 120 measurements were made, giving thicknesses grouped according to the law of chances around 4.4 mµ. It is certainly the best measurement made so far of the thickness of the “black spot ” for which Johonnott gave 6 mµ. The extreme thinness of this band, the faintness of the reflected light, and the difficulties due to parasitic lights make this determination particularly interesting. The set of the measurements for the first fifteen bands give similarly thicknesses which are, within several hundredths, of the successive multiples of 4.5 mµ. As this elementary thickness is not known with a precision greater than 4 per cent, it seems impossible to verify the law above a certain thickness. For example, at this accuracy any thickness greater than 120 mµ would be a multiple of 4.5 mµ. But if the law exists, the thickness should always vary in the same way between two adjacent areas; or again the “step of the stairs” should remain the same, and this can be verified. This is, in fact, what Wells saw, operating this time in white light and using a method which René Marcelin had suggested to me in 1914, by obtaining tints identical to those of the lamina by means of a quartz compensator of variable thickness which was placed between crossed nicols. (The difference between the thicknesses of quartz which gave the tints of the two adjacent liquid bands, determines the difference in thickness of these bands.) He obtained in this way 4.2 mµ near the first-order violet and 4.3 near the second-order violet. In short, the “step of the staircase” has the same value near the first, the fiftieth or the hundredth band, i.e. approximately 4.4 mµ; and we can be sure that: In a stratified liquid lamina the thickness of each band is a whole multiple of the same elementary thickness; in other words, it is very probable that: The bands of the stratified laminae are formed by the overlapping, in any number, of identical fundamental “sheets”. This is how a “discontinuous and periodic structure” of matter is perceived quite directly, at least in a certain group of cases. Similar experiments, suggested precisely by these observations of stratified laminae of soapy water, were made on mica at the beginning of 1914 by René Marcelin (who died for France in 1914). We know that if we pour selenium on to mica, and if we try to tear off this mica, thin laminae of mica remain adhering to the selenium. These laminae exhibit bright colourations which are divided into completely flat tints separated by clear rectilinear contours which mark discontinuities of thickness. The minimum difference of thickness measured with the Michel Levy comparator was found to be equal to 0.7 mµ which would, therefore, be the thickness of a monomolecular layer in the crystal. But the measuring accuracy becomes low for such a small thickness. Let us return to the stratified laminae of soapy water for which the size of the discontinuities is such that we have readily accessible the elementary sheet the periodic repetition of which forms the bands. We shall want to know what this elementary sheet is. I see in it a monomolecular film of hydrated bioleate. We know, in fact (Rayleigh, A. Marcelin, Langmuir) that water on which float globules of oleic acid, is covered between these globules with a veil of oleic acid 1.9 mµ thick. According to its known density, this veil can be formed only by a single layer of molecules arranged perpendicularly to the surface and probably glued to the water by their (hygroscopic) acid groups. The surface of a soapy water is greasy (low surface tension, arrest of the movements of camphor); it is, therefore, covered at least by a similar layer of oleic acid or oleate, as can be shown by analysing a known quantity of soapy water drawn in the form of laminae having a known total surface area (Jean Perrin, Mouquin). The black spot corresponding to the maximum possible thinning would, therefore, be a kind of sandwich containing a layer of water molecules against each side of which, and glued to it by their acid groups, parallel molecules of oleic acid or oleate are arranged, the whole forming an anisotropic lamina or liquid crystalline sheet. The piling-up of such sheets, easily sliding over each other – with weak cohesion forces existing between them – would give the successive bands. In remarkable agreement with this conception is the fact that the molecular length as calculated for oleic acid from X-ray diffraction measurements recently made in the laboratories of Bragg and Friedel agrees with the thickness of our fundamental sheet. I do not think that there is any more to be said, at the moment, on the direct visibility of molecules. The discontinuous structure of the atom Even whilst evidence continued to accumulate on the still disputed atomic reality, a start was made to penetrate the interior structure of these atoms, a research in which Rutherford and Bohr obtained marvellous results, as we know. And I must summarize here my contribution to this research. It was known that when an electric discharge passes in a glass tube through a sufficiently rarefied gas, the part facing the cathode is illuminated by a fluorescence on which the shadow of any obstacle placed in front of the cathode is outlined; and that the cathode rays definable in this way, are deflected by the magnetic field, describing a circular trajectory when they are thrown at right angles to a uniform field (Hittorf). Crookes had had the intuition that these rays were trajectories of negative particles emitted by the cathode and violently repelled by it (1886), but he did not succeed in establishing this electrification. And this emission theory was abandoned when Hertz on the one hand failed in his attempts to manifest the negative electricity of the rays, and on the other hand showed that they were able to pass through glass foil or aluminium foil several microns thick. It was assumed since then that the cathode rays were immaterial and had a wave-like nature similar to light. This opinion was held principally by Lenard (1894) who showed that these rays can leave the tube where they are formed, through a “window” made of a fairly thick foil to support the atmospheric pressure, and that they can be studied in this way in any gas or in an absolute vacuum. It seemed to me, however, that the electrified projectiles imagined by Crookes might differ sufficiently, in size and in velocity, from ordinary molecules, to pass through walls which were impermeable to these molecules, and seeking to apply without complication the very definition of the electric charge, I made cathode rays penetrate into a “Faraday cylinder” contained inside a protective chamber. As soon as the rays (which can, first, be drawn aside by a magnetic field which is just strong enough to do so) enter the cylinder, the latter presents phenomena which give precisely the definition of a negative electric charge, and which enable it to be measured (1895). This experiment was successful even when the protective chamber was entirely closed, the rays penetrating it through a thin metal foil. Almost at the same time I showed (1896) that cathode rays are deflected by an electric field, and that there is a method here for measuring the drop in potential which had until then been unknown and from which they obtained their energy. These experiments were at once repeated, and confirmed, by Lenard himself (whose theory they ruined), by Wiechert, by Wien, and by J.J. Thomson. I had begun to make measurements which were intended to give the velocity (obviously variable according to the circumstances) of the cathode projectiles and the e/m ratio of its charge to its mass, supplementing the measurement of the drop in potential with that of the magnetic field capable of producing a given deflection. I was anticipated here by J. J. Thomson who in the very paper in which he published the confirmation of my experiments showed that once the electrification of the rays had been demonstrated, it was easy to obtain the velocity and the charge of the projectiles from the action of the electrical field and the magnetic field. He found that the e/m ratio, independently of all the circumstances, is approximately 2,000 times greater than it is for hydrogen in electrolysis, and consequently he had the honour of proving that the cathode projectile is much lighter than the hydrogen atom (1897). The experimental idea of the electron as a universal subatomic constituent was therefore reached, and my experiments had played a certain part in this growth of our knowledge of the manner in which matter is discontinuous. The problem of the structure of the atom was immediately raised as it ceased to be the ultimate unit of matter. J. J. Thomson assumed that whilst the atom as a whole was neutral, it consisted of a homogeneous sphere of positive electricity inside which the electrons were held in such positions that the attractions and repulsions were in equilibrium. I was, I believe, the first to assume that the atom had a structure reminding to that of the solar system where the “planetary” electrons circulate around a positive “Sun”, the attraction by the centre being counterbalanced by the force of inertia (1901). But I never tried or even saw any means of verifying this conception. Rutherford (who had doubtless arrived at it independently, but who also had the delicacy to refer to the short phrase dropped during a lecture in which I had stated it) understood that the essential difference between his conception and that of J.J. Thomson was that there existed near the positive and quasi-punctual Sun, enormous electrical fields as compared with those which would exist inside or outside a homogeneous positive sphere having the same charge, but embracing the whole atom. The result was that if a positive charge which is itself quasi-punctual, is sufficiently fast to be able to pass near such a nucleus, it will be strongly deflected just as a comet can be deflected when it comes from the infinite and passes near the Sun. It was in this way (1911), that Rutherford discovered and explained that certain a rays (rays described by helium atoms projected by radioactive substances) undergo very strong deflections when they pass through a thin film, producing on a phosphorescent screen, really far from the mean impact of the bundle of rays, scintillations which mark their individual arrivals. All these deflections are explained quantitatively on condition that the nucleus is credited with a charge such that the number of planetary electrons is equal to the “rank number” of the atom in Mendeleev’s series. In this way each atom consists of an unimaginably small positive nucleus where almost the entire mass of the atom is concentrated and around which the planetary electrons, the presence of which determines the physical and chemical properties of the corresponding element. revolve at relatively colossal distances. The nucleus itself, lastly, has been revealed as being discontinuous and composed of hydrogen nuclei, or protons, which are possibly “cemented ” by nuclear electrons. As Prout had predicted, each atom can, in fact, be regarded as resulting from the condensation on a whole number of hydrogen atoms (the deviating elements having proved to be mixtures of isotopes, which confirm the law separately); the small differences which exist are explained (by applying Einstein’s law of the mass of energy) by the large variations of internal energy which may accompany these condensations (Langevin). And I have pointed out (1920) that the loss of energy which must then accompany the condensation of hydrogen into helium suffices alone to account for approximately one hundred milliard years of solar radiation at the present rate (the first theory to allow the understanding of the stupendous antiquity of climatic conditions only slightly different from the present conditions: the Helmholtz-Kelvin theory explained only a maximum of 50 million-years, a grossly insufficient figure as far as geology is concerned). This led me to think that the atoms of hydrogen, and then of helium (the only ones revealed by spectrum analysis in the non-resolvable nebulae) condense progressively, in the course of stellar evolution, into heavier and heavier atoms, radioactive disintegration being the exception and atomic integration being the rule. However, Rutherford succeeded in proving, in admirable experiments (1922), that when a nucleus of nitrogen, aluminium, or phosphorus is struck forcefully by an a projectile (sufficiently fast to “hit” it in spite of the electrical repulsion), a proton is expelled (a ray) with an energy which may exceed that of the a projectile, and Rutherford interpreted this transmutation as being the effect of an explosive disintegration (similar to that of a shell which is exploded by an impact). I maintained, on the contrary (1923), that there was then an integration, that the helium nucleus at first combines with the nucleus that it has hit, to form a radioactive atom (of a species as yet unknown) which soon expels a proton, and that there finally remains an atom which is three units heavier than the atom that has been hit. This has since been confirmed by Blackett (1925) in the very laboratory of Rutherford: three converging rays are counted (by the method of C.T.R. Wilson) when a Rutherford transmutation occurs, instead of the four which would exist if the striking projectile retained its individuality after the impact. But this refers rather to the evolution of Matter than to its discontinuity; if I were to say any more, I should be departing from the subject on which I came here to speak. *Similarly, the fact that there exists a definite isothermal radiation for each temperature, and that even a temperature is definable without the energy present in the form of radiation continuously gliding towards colours of increasingly smaller wavelengths, requires a structure to be discontinuous (Planck). From Nobel Lectures, Physics 1922-1941, Elsevier Publishing Company, Amsterdam, 1965 Copyright © The Nobel Foundation 1926 